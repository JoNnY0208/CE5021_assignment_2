{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b941698",
   "metadata": {},
   "source": [
    "# Assignment 2 â€“ Transfer Learning with MedMNIST\n",
    "\n",
    "This notebook implements a complete transfer learning pipeline on the **BloodMNIST** dataset from the MedMNIST collection using **ResNet-18** and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9113a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2, ToTensor\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from medmnist import BloodMNIST\n",
    "import medmnist\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('MedMNIST version:', medmnist.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & basic configuration\n",
    "DataClass = BloodMNIST\n",
    "info = medmnist.INFO[DataClass.flag]\n",
    "n_classes = len(info['label'])\n",
    "print('Using dataset:', DataClass.flag)\n",
    "print('Number of classes:', n_classes)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "download = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d49e2",
   "metadata": {},
   "source": [
    "## 1. Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = v2.Compose([\n",
    "    ToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomRotation(10),\n",
    "    v2.Normalize([0.485, 0.456, 0.406],\n",
    "                 [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transforms = v2.Compose([\n",
    "    ToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize([0.485, 0.456, 0.406],\n",
    "                 [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a127e3e",
   "metadata": {},
   "source": [
    "## 2. Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataClass(split='train', transform=train_transforms,\n",
    "                          download=download, size=224, mmap_mode='r')\n",
    "val_dataset   = DataClass(split='val',   transform=test_transforms,\n",
    "                          download=download, size=224, mmap_mode='r')\n",
    "test_dataset  = DataClass(split='test',  transform=test_transforms,\n",
    "                          download=download, size=224, mmap_mode='r')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader   = DataLoader(dataset=val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader  = DataLoader(dataset=test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fc94b",
   "metadata": {},
   "source": [
    "### Sample batch visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "axes = axes.flatten()\n",
    "for img, lbl, ax in zip(images[:8], labels[:8], axes):\n",
    "    img_show = img.permute(1, 2, 0).numpy()\n",
    "    img_show = (img_show - img_show.min()) / (img_show.max() - img_show.min() + 1e-8)\n",
    "    ax.imshow(img_show)\n",
    "    ax.set_title(f'label: {int(lbl)}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558e7be",
   "metadata": {},
   "source": [
    "## 3. Define Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc208aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'runs/bloodmnist_resnet18'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained ResNet-18 model\n",
    "try:\n",
    "    resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "except AttributeError:\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze backbone parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final FC layer\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, n_classes)\n",
    "\n",
    "model = resnet.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09946d1f",
   "metadata": {},
   "source": [
    "## 4. Optimisation & Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "best_model_path = 'best_bloodmnist_resnet18.pt'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.squeeze().long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    epoch_train_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.squeeze().long().to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            val_running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_val_loss = val_running_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_running_corrects.double() / len(val_dataset)\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar('Loss/train', epoch_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', epoch_val_loss, epoch)\n",
    "    writer.add_scalar('Acc/train', epoch_train_acc, epoch)\n",
    "    writer.add_scalar('Acc/val', epoch_val_acc, epoch)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch+1}/{num_epochs} '\n",
    "        f'Train loss: {epoch_train_loss:.4f} acc: {epoch_train_acc:.4f} | '\n",
    "        f'Val loss: {epoch_val_loss:.4f} acc: {epoch_val_acc:.4f}'\n",
    "    )\n",
    "\n",
    "    # Save best model\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f'Best validation accuracy: {best_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To launch TensorBoard inside e.g. Jupyter/Colab, you can use:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs\n",
    "print('To view logs, run TensorBoard pointing to:', log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b0947",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.squeeze().long().to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "classes = list(info['label'].values())\n",
    "print('Classes:', classes)\n",
    "print('Test samples:', len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp.plot(ax=ax, xticks_rotation=45)\n",
    "plt.title('Confusion Matrix - BloodMNIST (ResNet-18)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba69fc",
   "metadata": {},
   "source": [
    "## 6. Comments about your Approach\n",
    "\n",
    "- **Dataset choice**: I selected **BloodMNIST**, which consists of blood cell images with multiple classes. This allows me to demonstrate transfer learning on a realistic medical imaging dataset.\n",
    "- **Model & transfer learning strategy**: I used **ResNet-18** pretrained on ImageNet. I froze the convolutional backbone and only trained the final fully connected layer to keep training efficient and to avoid overfitting.\n",
    "- **Transforms & augmentation**: I applied random horizontal flips and small rotations to increase robustness, as well as normalisation using ImageNet mean and standard deviation so that the images match the statistics the pretrained backbone expects.\n",
    "- **Training setup**: I used Adam with learning rate 1e-3, batch size 64, and trained for 10 epochs. I monitored training and validation loss/accuracy using TensorBoard and saved the model with the best validation accuracy.\n",
    "- **Results**: The confusion matrix and classification report show how well the model performs per class. Any classes with lower precision/recall are candidates for further investigation.\n",
    "- **Potential improvements**: I could unfreeze some of the deeper ResNet layers and fine-tune them on BloodMNIST, use stronger data augmentation, or try alternative architectures (e.g., ResNet-34, EfficientNet) to potentially improve performance further."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
